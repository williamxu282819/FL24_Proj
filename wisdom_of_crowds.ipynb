{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marchitecture\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_images, train_labels, test_images, test_labels, val_images, val_labels \u001b[38;5;241m=\u001b[39m load_n_images(\u001b[38;5;241m2400\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "from load_data import *\n",
    "from architecture import *\n",
    "train_images, train_labels, test_images, test_labels, val_images, val_labels = load_n_images(2400)\n",
    "# make train_labels and test_labels binary: 0-4 -> 0, 5-9 -> 1\n",
    "# train_labels = np.array([0 if x < 5 else 1 for x in train_labels])\n",
    "# test_labels = np.array([0 if x < 5 else 1 for x in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cnn_run(args, seed, train_images, train_labels, test_images, test_labels, val_images, val_labels):\n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_dataset = TensorDataset(torch.Tensor(train_images).unsqueeze(1), torch.Tensor(train_labels).long())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.Tensor(val_images).unsqueeze(1), torch.Tensor(val_labels).long())\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.Tensor(test_images).unsqueeze(1), torch.Tensor(test_labels).long())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate models\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    encoder = Encoder(args).to(device)\n",
    "    classifier = Class_out(args).to(device)\n",
    "    conf_out = Conf_out(args).to(device)\n",
    "\n",
    "    # Define loss functions and optimizer\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_conf = nn.BCELoss()  # Binary Cross Entropy for confidence prediction\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()) + list(conf_out.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    # Run the CNN denoise training loop\n",
    "    best_model, best_z, best_conv_flat, test_z, test_conv_flat, stats = CNN_denoise(\n",
    "        encoder=encoder,\n",
    "        classifier=classifier,\n",
    "        conf_out=conf_out,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        criterion_class=criterion_class,\n",
    "        criterion_conf=criterion_conf,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Return or log the results\n",
    "    results = {\n",
    "        #'best_model': best_model,        # Contains state_dicts of encoder, classifier, conf_out\n",
    "        'best_train_z': best_z.numpy(),         # Latent vectors for training set\n",
    "        'best_train_conv_flat': best_conv_flat.numpy(),  # Flattened conv layer output for training set\n",
    "        'best_test_z': test_z.numpy(),           # Latent vectors for test set\n",
    "        'best_test_conv_flat': test_conv_flat.numpy(),   # Flattened conv layer output for test set\n",
    "        'stats': stats                  # Training statistics\n",
    "    }\n",
    "\n",
    "    one_cnn_stats = stats\n",
    "    print(one_cnn_stats)\n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_acc': 0.8561, 'train_conf': 0.9334, 'test_acc': 0.8688, 'test_conf': 0.9335, 'best_loss': 0.6871, 'best_acc': 0.8906, 'best_conf': 0.8931}\n",
      "{'train_acc': 0.8486, 'train_conf': 0.9732, 'test_acc': 0.8172, 'test_conf': 0.9736, 'best_loss': 0.6951, 'best_acc': 0.8906, 'best_conf': 0.7834}\n",
      "{'train_acc': 0.8405, 'train_conf': 0.9398, 'test_acc': 0.8276, 'test_conf': 0.9421, 'best_loss': 0.6885, 'best_acc': 0.8906, 'best_conf': 0.8478}\n",
      "{'train_acc': 0.8825, 'train_conf': 0.9489, 'test_acc': 0.8714, 'test_conf': 0.9482, 'best_loss': 0.494, 'best_acc': 0.9531, 'best_conf': 0.8616}\n",
      "{'train_acc': 0.8157, 'train_conf': 0.9615, 'test_acc': 0.8125, 'test_conf': 0.9603, 'best_loss': 0.5817, 'best_acc': 0.9375, 'best_conf': 0.8487}\n",
      "{'train_acc': 0.8723, 'train_conf': 0.9566, 'test_acc': 0.8198, 'test_conf': 0.9562, 'best_loss': 0.475, 'best_acc': 0.9375, 'best_conf': 0.9216}\n",
      "{'train_acc': 0.8863, 'train_conf': 0.9643, 'test_acc': 0.8427, 'test_conf': 0.9625, 'best_loss': 0.5655, 'best_acc': 0.9062, 'best_conf': 0.9085}\n",
      "{'train_acc': 0.7645, 'train_conf': 0.919, 'test_acc': 0.7536, 'test_conf': 0.9172, 'best_loss': 0.304, 'best_acc': 0.9688, 'best_conf': 0.8706}\n",
      "{'train_acc': 0.8766, 'train_conf': 0.9353, 'test_acc': 0.863, 'test_conf': 0.9318, 'best_loss': 0.6384, 'best_acc': 0.8906, 'best_conf': 0.8263}\n",
      "{'train_acc': 0.8168, 'train_conf': 0.9591, 'test_acc': 0.7807, 'test_conf': 0.959, 'best_loss': 0.4998, 'best_acc': 0.9219, 'best_conf': 0.8148}\n"
     ]
    }
   ],
   "source": [
    "train_zs = []\n",
    "train_conv_flats = []\n",
    "test_zs = []\n",
    "test_conv_flats = []\n",
    "loop_num = 10\n",
    "\n",
    "# Hyperparameters\n",
    "class Args:\n",
    "    latent_dim = 64 # 10, 32, 64, 128, 256... this would cause PCA testing accuracy to go up\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    learning_rate = 0.01\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Run the CNN denoise training loop\n",
    "for seed in range(loop_num):\n",
    "    results = one_cnn_run(args, seed, train_images, train_labels, test_images, test_labels)\n",
    "    train_zs.append(results['best_train_z'])\n",
    "    train_conv_flats.append(results['best_train_conv_flat'])\n",
    "    test_zs.append(results['best_test_z'])\n",
    "    test_conv_flats.append(results['best_test_conv_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set using PCA: 88.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pca, test_pca, train_reconstructed, test_reconstructed = PCA_reduction(train_images, test_images, args.latent_dim, random_seed=0)\n",
    "# Logistic regression classifier for PCA-based latent space\n",
    "clf_pca = LogisticRegression(max_iter=loop_num)\n",
    "clf_pca.fit(train_pca, train_labels)  # Train on PCA latent space\n",
    "test_preds_pca = clf_pca.predict(test_pca)  # Predict on test set\n",
    "# Compute accuracy\n",
    "acc_pca = accuracy_score(test_labels, test_preds_pca)\n",
    "print(f\"Accuracy on test set using PCA: {acc_pca * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.1767\n",
      "Average confidence of predictions: 0.1321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "def vote_majority(X):\n",
    "    # along the second axis, find the most common element\n",
    "    return np.array([Counter(column).most_common(1)[0][0] for column in X.T])\n",
    "\n",
    "# Initialize a list to store the decision trees\n",
    "decision_trees = []\n",
    "prediction_trees = []\n",
    "prediction_trees_probs = []\n",
    "\n",
    "for i in range(loop_num): \n",
    "    # # Create a new decision tree\n",
    "    tree = DecisionTreeClassifier(max_depth=3, random_state=i, max_features=8) # change max_features according to latent_dim\n",
    "    # tree = RandomForestClassifier(n_estimators=loop_num, max_depth=5, random_state=i, max_features=64)\n",
    "    # Fit the decision tree on the latent representations\n",
    "    training_array = train_zs[i]\n",
    "    tree.fit(training_array, train_labels)\n",
    "    # Append the decision tree to the list\n",
    "    decision_trees.append(tree)\n",
    "\n",
    "    # Predict the test labels using the decision tree\n",
    "    testing_array = test_zs[i]\n",
    "    \n",
    "    prediction_tree = tree.predict(testing_array)\n",
    "    prediction_trees.append(prediction_tree)\n",
    "\n",
    "    # Predict the test labels using the decision tree and calculate the probabilities\n",
    "    prediction_tree_probs = tree.predict_proba(testing_array)\n",
    "    prediction_trees_probs.append(prediction_tree_probs)\n",
    "\n",
    "prediction_trees = np.array(prediction_trees)\n",
    "prediction_trees_probs = np.array(prediction_trees_probs)\n",
    "\n",
    "# vote for the majority\n",
    "rf_predictions = vote_majority(prediction_trees)\n",
    "# calculate the accuracy\n",
    "print(f\"Testing accuracy: {accuracy_score(test_labels, rf_predictions):.4f}\")\n",
    "# Calculate the average probability for each class across all trees\n",
    "average_probs = np.mean(prediction_trees_probs, axis=0)\n",
    "# Calculate the average confidence of the predictions\n",
    "average_confidences = np.max(average_probs, axis=1)\n",
    "average_confidence = np.mean(average_confidences)\n",
    "print(f\"Average confidence of predictions: {average_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.1333\n",
      "Average confidence of predictions: 0.1234\n"
     ]
    }
   ],
   "source": [
    "# do the same analysis using XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize a list to store the XGBoost models\n",
    "xgboost_models = []\n",
    "prediction_xgboost = []\n",
    "prediction_xgboost_probs = []\n",
    "\n",
    "for i in range(loop_num):\n",
    "    # Create a new XGBoost model\n",
    "    xgboost = XGBClassifier(n_estimators=loop_num, random_state=i, learning_rate=0.1)\n",
    "    # Fit the XGBoost model on the latent representations\n",
    "    training_array = train_zs[i]\n",
    "    xgboost.fit(training_array, train_labels)\n",
    "    # Append the XGBoost model to the list\n",
    "    xgboost_models.append(xgboost)\n",
    "\n",
    "    # Predict the test labels using the XGBoost model\n",
    "    testing_array = test_zs[i]\n",
    "    prediction_xgb = xgboost.predict(testing_array)\n",
    "    prediction_xgboost.append(prediction_xgb)\n",
    "\n",
    "    # Predict the test labels using the XGBoost model and calculate the probabilities\n",
    "    prediction_xgb_probs = xgboost.predict_proba(testing_array)\n",
    "    prediction_xgboost_probs.append(prediction_xgb_probs)\n",
    "\n",
    "prediction_xgboost = np.array(prediction_xgboost)\n",
    "prediction_xgboost_probs = np.array(prediction_xgboost_probs)\n",
    "\n",
    "# vote for the majority\n",
    "xgboost_predictions = vote_majority(prediction_xgboost)\n",
    "# calculate the accuracy\n",
    "print(f\"Testing accuracy: {accuracy_score(test_labels, xgboost_predictions):.4f}\")\n",
    "# Calculate the average probability for each class across all trees\n",
    "average_probs = np.mean(prediction_xgboost_probs, axis=0)\n",
    "# Calculate the average confidence of the predictions\n",
    "average_confidences = np.max(average_probs, axis=1)\n",
    "average_confidence = np.mean(average_confidences)\n",
    "print(f\"Average confidence of predictions: {average_confidence:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
