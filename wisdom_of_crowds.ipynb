{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from binary_architecture import *\n",
    "train_images, train_labels, test_images, test_labels = load_n_images(1200)\n",
    "# make train_labels and test_labels binary: 0-4 -> 0, 5-9 -> 1\n",
    "train_labels = np.array([0 if x < 5 else 1 for x in train_labels])\n",
    "test_labels = np.array([0 if x < 5 else 1 for x in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cnn_run(args, seed, train_images, train_labels, test_images, test_labels):\n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_dataset = TensorDataset(torch.Tensor(train_images).unsqueeze(1), torch.Tensor(train_labels).long())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.Tensor(test_images).unsqueeze(1), torch.Tensor(test_labels).long())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate models\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    encoder = Encoder(args).to(device)\n",
    "    classifier = Class_out(args).to(device)\n",
    "    conf_out = Conf_out(args).to(device)\n",
    "\n",
    "    # Define loss functions and optimizer\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_conf = nn.BCELoss()  # Binary Cross Entropy for confidence prediction\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()) + list(conf_out.parameters()), lr=args.learning_rate)\n",
    "\n",
    "    # Run the CNN denoise training loop\n",
    "    best_model, test_z, test_conv_flat, stats = CNN_denoise(\n",
    "        encoder=encoder,\n",
    "        classifier=classifier,\n",
    "        conf_out=conf_out,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        criterion_class=criterion_class,\n",
    "        criterion_conf=criterion_conf,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Return or log the results\n",
    "    results = {\n",
    "        'best_model': best_model,\n",
    "        'stats': stats\n",
    "    }\n",
    "\n",
    "    one_cnn_stats = stats\n",
    "    print(one_cnn_stats)\n",
    "    # Return the results\n",
    "    return results, test_z, test_conv_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_acc': 0.8332, 'test_conf': 0.7897, 'best_loss': 0.6048, 'best_acc': 0.8906, 'best_conf': 0.9184}\n",
      "{'test_acc': 0.6767, 'test_conf': 0.9556, 'best_loss': 0.4113, 'best_acc': 0.9531, 'best_conf': 0.8685}\n",
      "{'test_acc': 0.802, 'test_conf': 0.879, 'best_loss': 0.6792, 'best_acc': 0.875, 'best_conf': 0.8663}\n",
      "{'test_acc': 0.8483, 'test_conf': 0.9328, 'best_loss': 0.2611, 'best_acc': 1.0, 'best_conf': 0.8178}\n",
      "{'test_acc': 0.7128, 'test_conf': 0.9807, 'best_loss': 0.1701, 'best_acc': 1.0, 'best_conf': 0.9416}\n",
      "{'test_acc': 0.7636, 'test_conf': 0.7797, 'best_loss': 0.2795, 'best_acc': 1.0, 'best_conf': 0.8794}\n",
      "{'test_acc': 0.8588, 'test_conf': 0.9331, 'best_loss': 0.5104, 'best_acc': 0.9219, 'best_conf': 0.868}\n",
      "{'test_acc': 0.8824, 'test_conf': 0.921, 'best_loss': 0.3363, 'best_acc': 1.0, 'best_conf': 0.7728}\n",
      "{'test_acc': 0.8469, 'test_conf': 0.9053, 'best_loss': 0.5226, 'best_acc': 0.9062, 'best_conf': 0.9593}\n",
      "{'test_acc': 0.8293, 'test_conf': 0.8989, 'best_loss': 0.287, 'best_acc': 1.0, 'best_conf': 0.8748}\n"
     ]
    }
   ],
   "source": [
    "loop_num = 10\n",
    "\n",
    "# Hyperparameters\n",
    "class Args:\n",
    "    latent_dim = 64 # 10, 32, 64, 128, 256... this would cause PCA testing accuracy to go up\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    learning_rate = 0.01\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Run the CNN denoise training loop\n",
    "for seed in range(loop_num):\n",
    "    results, _, _ = one_cnn_run(args, seed, train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set using PCA: 84.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pca, test_pca, train_reconstructed, test_reconstructed = PCA_reduction(train_images, test_images, args.latent_dim, random_seed=0)\n",
    "# Logistic regression classifier for PCA-based latent space\n",
    "clf_pca = LogisticRegression(max_iter=loop_num)\n",
    "clf_pca.fit(train_pca, train_labels)  # Train on PCA latent space\n",
    "test_preds_pca = clf_pca.predict(test_pca)  # Predict on test set\n",
    "# Compute accuracy\n",
    "acc_pca = accuracy_score(test_labels, test_preds_pca)\n",
    "print(f\"Accuracy on test set using PCA: {acc_pca * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.1767\n",
      "Average confidence of predictions: 0.1321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "def vote_majority(X):\n",
    "    # along the second axis, find the most common element\n",
    "    return np.array([Counter(column).most_common(1)[0][0] for column in X.T])\n",
    "\n",
    "# Initialize a list to store the decision trees\n",
    "decision_trees = []\n",
    "prediction_trees = []\n",
    "prediction_trees_probs = []\n",
    "\n",
    "for i in range(loop_num): \n",
    "    # # Create a new decision tree\n",
    "    tree = DecisionTreeClassifier(max_depth=3, random_state=i, max_features=8) # change max_features according to latent_dim\n",
    "    # tree = RandomForestClassifier(n_estimators=loop_num, max_depth=5, random_state=i, max_features=64)\n",
    "    # Fit the decision tree on the latent representations\n",
    "    training_array = train_zs[i]\n",
    "    tree.fit(training_array, train_labels)\n",
    "    # Append the decision tree to the list\n",
    "    decision_trees.append(tree)\n",
    "\n",
    "    # Predict the test labels using the decision tree\n",
    "    testing_array = test_zs[i]\n",
    "    \n",
    "    prediction_tree = tree.predict(testing_array)\n",
    "    prediction_trees.append(prediction_tree)\n",
    "\n",
    "    # Predict the test labels using the decision tree and calculate the probabilities\n",
    "    prediction_tree_probs = tree.predict_proba(testing_array)\n",
    "    prediction_trees_probs.append(prediction_tree_probs)\n",
    "\n",
    "prediction_trees = np.array(prediction_trees)\n",
    "prediction_trees_probs = np.array(prediction_trees_probs)\n",
    "\n",
    "# vote for the majority\n",
    "rf_predictions = vote_majority(prediction_trees)\n",
    "# calculate the accuracy\n",
    "print(f\"Testing accuracy: {accuracy_score(test_labels, rf_predictions):.4f}\")\n",
    "# Calculate the average probability for each class across all trees\n",
    "average_probs = np.mean(prediction_trees_probs, axis=0)\n",
    "# Calculate the average confidence of the predictions\n",
    "average_confidences = np.max(average_probs, axis=1)\n",
    "average_confidence = np.mean(average_confidences)\n",
    "print(f\"Average confidence of predictions: {average_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.1333\n",
      "Average confidence of predictions: 0.1234\n"
     ]
    }
   ],
   "source": [
    "# do the same analysis using XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize a list to store the XGBoost models\n",
    "xgboost_models = []\n",
    "prediction_xgboost = []\n",
    "prediction_xgboost_probs = []\n",
    "\n",
    "for i in range(loop_num):\n",
    "    # Create a new XGBoost model\n",
    "    xgboost = XGBClassifier(n_estimators=loop_num, random_state=i, learning_rate=0.1)\n",
    "    # Fit the XGBoost model on the latent representations\n",
    "    training_array = train_zs[i]\n",
    "    xgboost.fit(training_array, train_labels)\n",
    "    # Append the XGBoost model to the list\n",
    "    xgboost_models.append(xgboost)\n",
    "\n",
    "    # Predict the test labels using the XGBoost model\n",
    "    testing_array = test_zs[i]\n",
    "    prediction_xgb = xgboost.predict(testing_array)\n",
    "    prediction_xgboost.append(prediction_xgb)\n",
    "\n",
    "    # Predict the test labels using the XGBoost model and calculate the probabilities\n",
    "    prediction_xgb_probs = xgboost.predict_proba(testing_array)\n",
    "    prediction_xgboost_probs.append(prediction_xgb_probs)\n",
    "\n",
    "prediction_xgboost = np.array(prediction_xgboost)\n",
    "prediction_xgboost_probs = np.array(prediction_xgboost_probs)\n",
    "\n",
    "# vote for the majority\n",
    "xgboost_predictions = vote_majority(prediction_xgboost)\n",
    "# calculate the accuracy\n",
    "print(f\"Testing accuracy: {accuracy_score(test_labels, xgboost_predictions):.4f}\")\n",
    "# Calculate the average probability for each class across all trees\n",
    "average_probs = np.mean(prediction_xgboost_probs, axis=0)\n",
    "# Calculate the average confidence of the predictions\n",
    "average_confidences = np.max(average_probs, axis=1)\n",
    "average_confidence = np.mean(average_confidences)\n",
    "print(f\"Average confidence of predictions: {average_confidence:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
